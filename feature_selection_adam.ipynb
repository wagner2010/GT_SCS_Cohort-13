{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to select features for machine learning\n",
    "\n",
    "Which features do you use? All of them? Some of them?\n",
    "    \n",
    "__Remember__: Our goal is to find the smallest set of the available features such that the fitted model will reach its maximal predictive value. \n",
    "    \n",
    "### Why?     \n",
    " - Less complexity = reduced bias    \n",
    " - Lower dimensional space = less computation time    \n",
    " - Fewer variables = better interpretability    \n",
    " \n",
    "### How to pick?    \n",
    " - Domain expertise    \n",
    " - Regularization techniques    \n",
    " - Transformer methods    \n",
    " - Dimensionality reduction    \n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCCUPANCY = ('http://bit.ly/ddl-occupancy-dataset', 'occupancy.zip')\n",
    "CREDIT    = ('http://bit.ly/ddl-credit-dataset', 'credit.xls')\n",
    "CONCRETE  = ('http://bit.ly/ddl-concrete-data', 'concrete.xls')\n",
    "\n",
    "def download_data(url, name, path='data'):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    with open(os.path.join(path, name), 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "\n",
    "def download_all(path='data'):\n",
    "    for href, name in (OCCUPANCY, CREDIT, CONCRETE):\n",
    "        download_data(href, name, path)\n",
    "\n",
    "    # Extract the occupancy zip data\n",
    "    z = zipfile.ZipFile(os.path.join(path, 'occupancy.zip'))\n",
    "    z.extractall(os.path.join(path, 'occupancy'))\n",
    "\n",
    "path='data'\n",
    "download_all(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the first dataset into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the room occupancy dataset into a dataframe\n",
    "occupancy = os.path.join('data','occupancy','datatraining.txt')\n",
    "occupancy = pd.read_csv(occupancy, sep=',')\n",
    "occupancy.columns = [\n",
    "    'date', 'temp', 'humid', 'light', 'co2', 'hratio', 'occupied'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate dataframe into features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = occupancy[['temp', 'humid', 'light', 'co2', 'hratio']]\n",
    "labels   = occupancy['occupied']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temp', 'humid', 'light', 'co2', 'hratio']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization techniques\n",
    "\n",
    "### LASSO  (L1 Regularization) \n",
    "LASSO forces weak features to have zeroes as coefficients, effectively dropping the least predictive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('temp', -0.0), ('humid', 0.0), ('light', 0.001604039030371534), ('co2', 0.0002566541934433866), ('hratio', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "#LASSO forces out weak features to have 0 coefficient (dropping them).-L1\n",
    "model = Lasso()\n",
    "model.fit(features, labels)\n",
    "print(list(zip(features, model.coef_.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression (L2 Regularization) \n",
    "Ridge assigns every feature a weight, but spreads the coefficient values out more equally, shrinking but still maintaining less predictive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('temp', -0.06273198200152029), ('humid', -0.0024965287829986226), ('light', 0.0017625248355878475), ('co2', 0.00033448323910357223), ('hratio', 0.004924465342955606)]\n"
     ]
    }
   ],
   "source": [
    "#Ridge assigns weigths to every featuer shrinking less predictive features in concert with all features. -L2\n",
    "model = Ridge()\n",
    "model.fit(features, labels)\n",
    "print(list(zip(features, model.coef_.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet\n",
    "ElasticNet is a linear combination of L1 and L2 regularization, meaning it combines Ridge and LASSO and essentially splits the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('temp', -0.0), ('humid', 0.0), ('light', 0.0016178824800305253), ('co2', 0.0002560187107121839), ('hratio', -0.0)]\n"
     ]
    }
   ],
   "source": [
    "#ENet is a linear combination of L1 and L2 (combines Ridge and LASSO)\n",
    "model = ElasticNet()\n",
    "model.fit(features, labels)\n",
    "print(list(zip(features, model.coef_.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer methods    \n",
    "\n",
    "### `SelectFromModel()` \n",
    "Scikit-Learn has a meta-transformer method for selecting features based on importance weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['light', 'co2']\n"
     ]
    }
   ],
   "source": [
    "#LASSO demo select from model--will select 'importance' based on weights\n",
    "model = Lasso()\n",
    "sfm = SelectFromModel(model)\n",
    "sfm.fit(features, labels)\n",
    "print(list(features.iloc[:, sfm.get_support(indices=True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp']\n"
     ]
    }
   ],
   "source": [
    "#Ridge demo select from model--will select 'importance' based on weights\n",
    "model = Ridge()\n",
    "sfm = SelectFromModel(model)\n",
    "sfm.fit(features, labels)\n",
    "print(list(features.iloc[:, sfm.get_support(indices=True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['light']\n"
     ]
    }
   ],
   "source": [
    "#ElasticNet demo select from model--will select 'importance' based on weights\n",
    "\n",
    "model = ElasticNet()\n",
    "sfm = SelectFromModel(model)\n",
    "sfm.fit(features, labels)\n",
    "print(list(features.iloc[:, sfm.get_support(indices=True)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction\n",
    "\n",
    "### Principal component analysis (PCA)\n",
    "Linear dimensionality reduction using Singular Value Decomposition (SVD) of the data and keeping only the most significant singular vectors to project the data into a lower dimensional space.\n",
    "\n",
    " - Unsupervised method\n",
    " - Uses a signal representation criterion\n",
    " - Identifies the combination of attributes that account for the most variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[239.75415116 222.70021675]\n",
      " [234.83734556 229.07352309]\n",
      " [232.82363564 226.1680712 ]\n",
      " ...\n",
      " [312.01464185 194.23928716]\n",
      " [331.53968882 184.46791921]\n",
      " [338.40133606 196.6888825 ]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "new_features = pca.fit(features).transform(features)\n",
    "print(new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear discriminant analysis (LDA)\n",
    "A classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayesâ€™ rule. The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix. Can be used to reduce the dimensionality of the input by projecting it to the most discriminative directions.\n",
    "\n",
    "- Supervised method\n",
    "- Uses a classification criterion\n",
    "- Tries to identify attributes that account for the most variance between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.44457859]\n",
      " [3.4827798 ]\n",
      " [3.43530287]\n",
      " ...\n",
      " [4.25852644]\n",
      " [4.29565825]\n",
      " [4.4748546 ]]\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(n_components=2)\n",
    "new_features = lda.fit(features, labels).transform(features)\n",
    "print(new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about feature selection tools within Scikit-Learn, check out http://scikit-learn.org/stable/modules/feature_selection.html.\n",
    "\n",
    "## Exercises\n",
    "Try out the above techniques yourself with the Credit Card Default and Concrete Strength datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you have pip installed xlrd\n",
    "# Load the credit card default dataset into a dataframe\n",
    "credit = os.path.join('data','credit.xls')\n",
    "credit = pd.read_excel(credit, header=1)\n",
    "credit.columns = [\n",
    "    'id', 'limit', 'sex', 'edu', 'married', 'age', 'apr_delay', 'may_delay',\n",
    "    'jun_delay', 'jul_delay', 'aug_delay', 'sep_delay', 'apr_bill', 'may_bill',\n",
    "    'jun_bill', 'jul_bill', 'aug_bill', 'sep_bill', 'apr_pay', 'may_pay', 'jun_pay',\n",
    "    'jul_pay', 'aug_pay', 'sep_pay', 'default'\n",
    "]\n",
    "\n",
    "# Separate dataframe into features and targets\n",
    "cred_features = credit[[\n",
    "    'limit', 'sex', 'edu', 'married', 'age', 'apr_delay', 'may_delay',\n",
    "    'jun_delay', 'jul_delay', 'aug_delay', 'sep_delay', 'apr_bill', 'may_bill',\n",
    "    'jun_bill', 'jul_bill', 'aug_bill', 'sep_bill', 'apr_pay', 'may_pay',\n",
    "    'jun_pay', 'jul_pay', 'aug_pay', 'sep_pay'\n",
    "]]\n",
    "cred_labels = credit['default']\n",
    "\n",
    "\n",
    "# Load the concrete compression dataset into a dataframe\n",
    "concrete = pd.read_excel(os.path.join('data','concrete.xls'))\n",
    "concrete.columns = [\n",
    "    'cement', 'slag', 'ash', 'water', 'splast',\n",
    "    'coarse', 'fine', 'age', 'strength'\n",
    "]\n",
    "\n",
    "# Separate dataframe into features and targets\n",
    "conc_features = concrete[[\n",
    "    'cement', 'slag', 'ash', 'water', 'splast', 'coarse', 'fine', 'age'\n",
    "]]\n",
    "conc_labels = concrete['strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cement', 'slag', 'ash', 'water', 'splast', 'coarse', 'fine', 'age']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List Features\n",
    "list(conc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cement', 0.11830385490649789), ('slag', 0.10192312708923051), ('ash', 0.08692065036243565), ('water', -0.1679459525417401), ('splast', 0.22324101440120747), ('coarse', 0.014248476813369436), ('fine', 0.017337277629753935), ('age', 0.11375440243198076)]\n"
     ]
    }
   ],
   "source": [
    "#LASSO\n",
    "model = Lasso()\n",
    "model.fit(conc_features, conc_labels)\n",
    "print(list(zip(conc_features, model.coef_.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cement', 0.11978531126731268), ('slag', 0.10384729638533656), ('ash', 0.08794351927289551), ('water', -0.1503018798373258), ('splast', 0.290666261913905), ('coarse', 0.018029539615950222), ('fine', 0.020154207514373395), ('age', 0.11422560057934898)]\n"
     ]
    }
   ],
   "source": [
    "#Ridge\n",
    "model = Ridge()\n",
    "model.fit(conc_features, conc_labels)\n",
    "print(list(zip(conc_features, model.coef_.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cement', 0.11908714234987437), ('slag', 0.10292563560088508), ('ash', 0.08764411558867577), ('water', -0.16068677429011297), ('splast', 0.24817944283575386), ('coarse', 0.01588627715245208), ('fine', 0.01866789704444519), ('age', 0.11397596593916044)]\n"
     ]
    }
   ],
   "source": [
    "#ENET\n",
    "model = ElasticNet()\n",
    "model.fit(conc_features, conc_labels)\n",
    "print(list(zip(conc_features, model.coef_.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cement', 'slag', 'ash', 'water', 'splast', 'coarse', 'fine', 'age']\n"
     ]
    }
   ],
   "source": [
    "#Feat Select--LASSO\n",
    "model = Lasso()\n",
    "sfm = SelectFromModel(model)\n",
    "sfm.fit(conc_features, conc_labels)\n",
    "print(list(conc_features.iloc[:, sfm.get_support(indices=True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cement', 'water', 'splast', 'age']\n"
     ]
    }
   ],
   "source": [
    "#Feat Select--RIDGE\n",
    "model = Ridge()\n",
    "sfm = SelectFromModel(model)\n",
    "sfm.fit(conc_features, conc_labels)\n",
    "print(list(conc_features.iloc[:, sfm.get_support(indices=True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cement', 'water', 'splast', 'age']\n"
     ]
    }
   ],
   "source": [
    "#Feat Select--ElasticNet\n",
    "model = ElasticNet()\n",
    "sfm = SelectFromModel(model)\n",
    "sfm.fit(conc_features, conc_labels)\n",
    "print(list(conc_features.iloc[:, sfm.get_support(indices=True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 284.79397884  -10.36611049]\n",
      " [ 284.6574078   -14.48472503]\n",
      " [ 101.85095094  183.43561281]\n",
      " ...\n",
      " [-152.62039873   49.50233773]\n",
      " [-132.38216524   87.90567118]\n",
      " [ -29.20115611   48.36298599]]\n"
     ]
    }
   ],
   "source": [
    "#PCA_it\n",
    "pca = PCA(n_components=2)\n",
    "new_features = pca.fit(conc_features).transform(conc_features)\n",
    "print(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([79.98611076, 61.88736576, 40.26953526, ..., 23.69660064,\n       32.76803638, 32.40123514]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-01b964a530f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#LDA_it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconc_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconc_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconc_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \"\"\"\n\u001b[1;32m    429\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# estimate priors from sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([79.98611076, 61.88736576, 40.26953526, ..., 23.69660064,\n       32.76803638, 32.40123514]),)"
     ]
    }
   ],
   "source": [
    "#LDA_it\n",
    "lda = LDA(n_components=2)\n",
    "new_features = lda.fit(conc_features, conc_labels).transform(conc_features)\n",
    "print (new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
